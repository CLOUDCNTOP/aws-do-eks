apiVersion: "kubeflow.org/v1"
kind: PyTorchJob
metadata:
  name: pytorch-fsdp 
spec:
  elasticPolicy:
    rdzvBackend: etcd
    rdzvHost: etcd-service
    rdzvPort: 2379
    minReplicas: 1
    maxReplicas: 36
    maxRestarts: 100
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 80
  pytorchReplicaSpecs:
    Worker:
      replicas: 2
      restartPolicy: OnFailure
      template:
        metadata:
          labels:
            app: fsdp
        spec:
          volumes:
            - name: dshm
              emptyDir:
                medium: Memory
          nodeSelector:
            node.kubernetes.io/instance-type: "p4de.24xlarge"
            #node.kubernetes.io/instance-type: "g4dn.metal"
            #node.kubernetes.io/instance-type: "g5.2xlarge"
          affinity:
            podAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - fsdp
                topologyKey: "topology.kubernetes.io/zone"
          containers:
            - name: pytorch
              image: ${REGISTRY}${IMAGE}${TAG}
              imagePullPolicy: Always
              resources:
                requests:
                  nvidia.com/gpu: 8
                  vpc.amazonaws.com/efa: 4
                limits:
                  nvidia.com/gpu: 8
                  vpc.amazonaws.com/efa: 4
              env:
              - name: LOGLEVEL
                value: DEBUG
              - name: FI_PROVIDER
                value: efa
              - name: NCCL_DEBUG
                value: INFO
              command:
                - bash
                - -c
                - "torchrun --nproc-per-node=8 fsdp_train.py"
              volumeMounts:
                - mountPath: /dev/shm
                  name: dshm

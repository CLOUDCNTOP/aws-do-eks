#!/bin/bash

export AWS_REGION=us-west-2
export ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
export REGISTRY=${ACCOUNT}.dkr.ecr.${AWS_REGION}.amazonaws.com/
export IMAGE=fsdp
# DOCKERFILE_EXT=nanogpt-sockets|nanogpt-efa|llama2-sockets|llama2-efa
export DOCKERFILE_EXT=nanogpt-sockets
# FI_PROVIDER=sockets|efa
export FI_PROVIDER=sockets
export TAG=":${DOCKERFILE_EXT}"
export JOB_NAME=fsdp
export NUM_WORKERS=2
#export INSTANCE_TYPE=p5.48xlarge
export INSTANCE_TYPE=p4de.24xlarge
export GPU_PER_WORKER=8
export EFA_PER_WORKER=1
export NPROC_PER_WORKER=8
export RDZV_HOST=etcd
export RDZV_PORT=2379
# NanoGPT train command
export CMD="python -m torch.distributed.run --nproc-per-node=$NPROC_PER_WORKER fsdp_train.py"
# Llama2 train command
export HF_TOKEN="hf_InsertYourHugginfFaceLoginTokenHere"
export CMD="huggingface-cli login ${HF_TOKEN}; torchrun --nproc_per_node=${NPROC_PER_WORKER} --nnodes=${NUM_WORKERS} examples/finetuning.py --num_epochs=1 --batch_size_training=10 --use_peft --peft_method lora --pure_bf16 --use_fast_kernels --enable_fsdp --low_cpu_fsdp --model_name meta-llama/Llama-2-70b-hf --output_dir ."

